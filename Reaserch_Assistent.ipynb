{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP73DT6CDKWblrog18ZNbso",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranabilal09/Reaserch-Assistent/blob/main/Reaserch_Assistent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK6ZX_GF7wHx",
        "outputId": "5db9ab1f-d153-4bf4-b454-e4a05b775bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Reaserch-Assistent'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone  https://github.com/ranabilal09/Reaserch-Assistent.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet --upgrade langchain langgraph langchain-google-genai requests beautifulsoup4 python-dotenv"
      ],
      "metadata": {
        "id": "cE68iG76-U4C"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('Gemini_Api_Key')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langchai_api_key')\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = 'Research-Assistent'"
      ],
      "metadata": {
        "id": "ca20kNWc-gfe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "#prompt\n",
        "Template = \"\"\" {text}\n",
        "\n",
        "-------------------------\n",
        "\n",
        "Using the above context , answer in short the following question:\n",
        "\n",
        "> {question}\n",
        "\n",
        "If the question cannot be anwsered using the text , imply summarize the text. Include all the factual information , numbers and states etc. \"\"\"\n",
        "summary_prompt = ChatPromptTemplate.from_template(Template)\n",
        "\n",
        "url = \"https://blog.langchain.dev/announcing-langsmith/\"\n",
        "\n",
        "def scrape_url(url):\n",
        "  try:\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "      soup = BeautifulSoup(response.text, 'html.parser')\n",
        "      page_text = soup.get_text(separator=\" \" , strip = True)\n",
        "      return page_text\n",
        "    else:\n",
        "      return f\"failed to retrive the websearch , request status code:{response.status_code}\"\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return f\"Failed to retrieve the web search , An error occurred: {str(e)}\"\n",
        "\n",
        "page_content = scrape_url(url)[:10000]\n",
        "\n",
        "Chain = summary_prompt | ChatGoogleGenerativeAI(model= \"gemini-1.5-flash-8b\") | StrOutputParser()\n",
        "\n",
        "Chain.invoke({\n",
        "    \"question\":\"what is langsmith?\",\n",
        "    \"text\": page_content\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "n8TYs-Xo_MS6",
        "outputId": "b273ca73-49a8-463a-e6ec-a2ba2c46b667"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"LangSmith is a platform designed for building and iterating on LLM-powered applications.  It's a unified system for debugging, testing, evaluating, and monitoring these applications.  It provides deep visibility into model inputs and outputs, allows for easy dataset creation and testing of prompts/chains, integrates with evaluation modules (heuristic and LLM), and facilitates monitoring of application performance, costs, and user interactions.  LangSmith is currently in closed beta.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}